apiVersion: resource.aibee.cn/v1alpha1
kind: Pool
metadata:
  name: prod-cpu-pool
spec:
  nodeSelector:
    matchLabels:
      prod-cpu: "true"

#  supportResources:
#    - "gpu"

#  weight:
#    cpu: 2
#    nvidia.com/gpu: 0

#  quota:
#    cpu: "4"
#    nvidia.com/gpu: "10"
  priority: 10
  priorites:
    - name: "MostRequestedPriority"
      weight: 1

  disablePreemption: false
  disableBorrowing: false
  disableSharing: false
---
apiVersion: resource.aibee.cn/v1alpha1
kind: Pool
metadata:
  name: staging-cpu-pool
spec:
  nodeSelector:
    matchLabels:
      staging-cpu: "true"
  priority: 5
  disablePreemption: false
  disableBorrowing: false
  disableSharing: false
---
apiVersion: resource.aibee.cn/v1alpha1
kind: Pool
metadata:
  name: prod-gpu-pool
spec:
  nodeSelector:
    matchLabels:
      prod-gpu: "true"
  priority: 10
  disablePreemption: false
  disableBorrowing: false
  disableSharing: false
---
apiVersion: resource.aibee.cn/v1alpha1
kind: Pool
metadata:
  name: staging-gpu-pool
spec:
  nodeSelector:
    matchLabels:
      staging-gpu: "true"
  priority: 5
  disablePreemption: false
  disableBorrowing: false
  disableSharing: false
---
apiVersion: batch/v1
kind: Job
metadata:
  name: test-job
spec:
  parallelism: 4
  template:
    metadata:
      name: test-job
      annotations:
        resource.aibee.cn/pool: staging-gpu-pool
    spec:
      schedulerName: default-scheduler
      containers:
        - name: pi
          image: perl
          command: ["perl"]
          args: ["-Mbignum=bpi", "-wle", "print bpi(2000)"]
          resources:
            limits:
              cpu: 100m
            requests:
              cpu: 100m
      restartPolicy: Never
  backoffLimit: 1